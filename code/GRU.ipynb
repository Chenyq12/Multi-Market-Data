{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57f4cc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import logging\n",
    "from logging.handlers import RotatingFileHandler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.utils.data as Data\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.autograd import Variable\n",
    "from function import GRU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064e9a7a",
   "metadata": {},
   "source": [
    "# 数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9c82fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_data = pd.read_csv('../data/date.csv')\n",
    "# read_data = read_data.set_index('Date')\n",
    "# read_data = read_data.loc['2014-01-01':]\n",
    "# # read_data\n",
    "# fulldata = read_data[[\n",
    "# #                     'AS51',                         #0.431\n",
    "# #                  'CKLSE',                       #0.265\n",
    "# #                  'CSX5P',                   #0.318\n",
    "#                  'DJI',                 #0.43\n",
    "# #                  'FCHI',            #0.17\n",
    "# #                  'FTSE',        #0.58\n",
    "# #                  'GDAXI',   #0.391\n",
    "# #                  'HSI',      #0.374\n",
    "# #                  'IBOVESPA',   #0.298\n",
    "# #                  'IXIC',         #0.524\n",
    "# #                  'KS11',           #0.26\n",
    "# #                  'N225',            #0.621\n",
    "# #                  'RUT',              #0.6\n",
    "# #                  'SENSEX',            #0.282\n",
    "# #                  'SPTSX',               #0.39\n",
    "# #                  'SPX',                   #0.675\n",
    "# #                  'TWII',                    #0.3\n",
    "# #                  'shanghai',                    #0.074\n",
    "#                  'shenzheng']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c246dfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_data = pd.read_csv('../data/bond/date.csv')\n",
    "# read_data = read_data.set_index('Date')\n",
    "# read_data = read_data.loc['2014-01-01':]\n",
    "# fulldata = read_data[[\n",
    "# #                         'Australia',\n",
    "# #                       'Brazil',\n",
    "# #                       'Canada',\n",
    "# #                         'Germany',\n",
    "#                         'France',\n",
    "# #                       'Hongkong',\n",
    "# #                       'India',\n",
    "# #                       'Japan',\n",
    "# #                       'Malaysia',\n",
    "# #                       'US' ,\n",
    "#                       'Close']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d520a0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_data = pd.read_csv('../data/rate/date.csv')\n",
    "read_data = read_data.set_index('Date')\n",
    "read_data = read_data.loc['2014-01-01':]\n",
    "fulldata = read_data[[\n",
    "#                         'Australia',\n",
    "                       'Brazil',\n",
    "#                       'Canada',\n",
    "#                       'EU',\n",
    "#                       'Hongkong',\n",
    "#                       'India', \n",
    "#                       'Japan',\n",
    "#                       'Korea',\n",
    "#                       'Malaysia',\n",
    "#                       'Taiwan', \n",
    "#                       'UK',\n",
    "#                       'US' ,\n",
    "                      'Close']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e148ab17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = fulldata[['Close']]\n",
    "# fulldata = pd.concat([a, a], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1eb1118",
   "metadata": {},
   "source": [
    "# 参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11e50c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_day = 1             # 预测未来几天\n",
    "time_step = 25              # 这个参数很重要，是设置用前多少天的数据来预测，也是LSTM的time step数，请保证训练数据量大于它"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5306ceff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #超参数设置\n",
    "# batch_size = 32\n",
    "# hidden_size = 64           # gru的隐藏层大小，也是输出大小\n",
    "# gru_layers = 2             # gru的堆叠层数\n",
    "# dropout_rate = 0.001          # dropout概率\n",
    "# learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29997b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = len(fulldata.columns.tolist())\n",
    " # 数据参数\n",
    "if(c>2):\n",
    "    feature_columns = list(range(0, c-1))     # 要作为feature的列，按原数据从0开始计算，也可以用list 如 [2,4,6,8] 设置\n",
    "    label_columns = [c-1]                  # 要预测的列，按原数据从0开始计算, 如同时预测第四，五列 最低价和最高价\n",
    "else:\n",
    "    feature_columns = [0]\n",
    "    label_columns = [1]\n",
    "\n",
    "shuffle_train_data = True   # 是否对训练数据做shuffle\n",
    "random_seed = 32            # 随机种子，保证可复现\n",
    "\n",
    "train_data_rate = 0.80      # 训练数据占总体数据比例，测试数据就是 1-train_data_rate\n",
    "valid_data_rate = 0.20      # 验证数据占训练数据比例，验证集在训练过程使用，为了做模型和参数选择\n",
    "\n",
    "# do_continue_train = False    # 每次训练把上一次的final_state作为下一次的init_state，仅用于RNN类型模型，目前仅支持pytorch\n",
    "do_continue_train = True \n",
    "start_num_in_test = 0      # 测试集中前几天的数据会被删掉，因为它不够一个time_step\n",
    "\n",
    "data, data_column_name = fulldata.values, fulldata.columns.tolist()\n",
    "data_num = data.shape[0]\n",
    "train_num = int(data_num * train_data_rate)\n",
    "std = np.std(data, axis=0)\n",
    "mean = np.mean(data, axis=0)              # 数据的均值和方差\n",
    "norm_data = (data - mean)/std   # 归一化，去量纲"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f964520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义参数范围\n",
    "parameters = {\n",
    "    'Batch_size': [32, 64],\n",
    "    'Number_of_hidden_layers': [1,2,4],\n",
    "    'Number_of_neurons': [32,64,128],\n",
    "    'Learning_rate': [0.001,0.01],\n",
    "    'dropout_rate': [0.001,0.01]\n",
    "}\n",
    "\n",
    "# 生成所有可能的参数组合\n",
    "parameter_combinations = []\n",
    "for batch_size in parameters['Batch_size']:\n",
    "    for hidden_layer in parameters['Number_of_hidden_layers']:\n",
    "        for neurons in parameters['Number_of_neurons']:\n",
    "            for learning_rate in parameters['Learning_rate']:\n",
    "                for dropout_rate in parameters['dropout_rate']:\n",
    "                    parameter_combinations.append({\n",
    "                        'Batch_size': batch_size,\n",
    "                        'Number_of_hidden_layers': hidden_layer,\n",
    "                        'Number_of_neurons': neurons,\n",
    "                        'Learning_rate': learning_rate,\n",
    "                        'dropout_rate': dropout_rate\n",
    "                })\n",
    "\n",
    "# #打印所有参数组合\n",
    "# for idx, params in enumerate(parameter_combinations):\n",
    "#     print(f\"参数组合 {idx+1}: {params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b09e04f",
   "metadata": {},
   "source": [
    "# 初始化函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39066014",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_and_valid_data():\n",
    "#     feature_data = norm_data[:train_num, feature_columns]\n",
    "    feature_data = norm_data[:train_num]\n",
    "    label_data = norm_data[time_step : predict_day + train_num,\n",
    "                                    label_columns]    # 将延后几天的数据作为label\n",
    "\n",
    "    \n",
    "       # 在非连续训练模式下，每time_step行数据会作为一个样本，两个样本错开一行，比如：1-20行，2-21行。。。。\n",
    "    train_x = [feature_data[i:i+time_step] for i in range(train_num-time_step)]\n",
    "    train_y = [label_data[i:i+predict_day] for i in range(train_num-time_step)]\n",
    "\n",
    "    train_x, train_y = np.array(train_x), np.array(train_y)\n",
    "\n",
    "    train_x, valid_x, train_y, valid_y = train_test_split(train_x, train_y, test_size=valid_data_rate,\n",
    "                                                              random_state=random_seed,\n",
    "                                                              shuffle=shuffle_train_data)   # 划分训练和验证集，并打乱\n",
    "    \n",
    "    train_X, valid_X, train_Y, valid_Y = train_x, valid_x, train_y, valid_y\n",
    "    train_and_valid_data=[train_X, train_Y, valid_X, valid_Y]\n",
    "\n",
    "    train_X, train_Y, valid_X, valid_Y = train_and_valid_data\n",
    "    train_X, train_Y = torch.from_numpy(train_X).float(), torch.from_numpy(train_Y).float()     # 先转为Tensor\n",
    "    train_loader = DataLoader(TensorDataset(train_X, train_Y), batch_size=batch_size)    # DataLoader可自动生成可训练的batch数据\n",
    "\n",
    "    valid_X, valid_Y = torch.from_numpy(valid_X).float(), torch.from_numpy(valid_Y).float()\n",
    "    valid_loader = DataLoader(TensorDataset(valid_X, valid_Y), batch_size=batch_size)    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return train_loader, valid_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61592ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_data(pred_result, test_Y):\n",
    "    # 假设这是数据还原的函数\n",
    "    # 在这里实现将归一化后的数据还原成原始数据的过程\n",
    "    # 返回还原后的数据\n",
    "    std1 = std[1]\n",
    "    mean1 = mean[1]\n",
    "    true = test_Y*std1 + mean1\n",
    "    pred = pred_result*std1 + mean1\n",
    "    return pred, true\n",
    "\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "def train(model, dataloader, optimizer):\n",
    "    model.train()\n",
    "    train_losss = []\n",
    "    for seq, labels in train_loader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = model(seq)\n",
    "\n",
    "        # 假设你的目标张量为 target\n",
    "        labels = labels.squeeze(dim=2)\n",
    "        \n",
    "        y_pred = y_pred[:,-1]\n",
    "        labels = labels[:,-1]\n",
    "        y_pred = y_pred.squeeze()\n",
    "        losss = loss_function(y_pred, labels)\n",
    "\n",
    "        losss.backward()\n",
    "        optimizer.step()\n",
    "    train_losss.append(losss.detach().numpy())\n",
    "    return train_losss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def eval(model, dataloader):\n",
    "    model.eval()  # 评估模式\n",
    "    results = []\n",
    "    reals = []\n",
    "    valid_losss = []\n",
    "         # 先定义一个tensor保存预测结果\n",
    "    result_valid = torch.Tensor()\n",
    "    true_valid = torch.Tensor()\n",
    " \n",
    "    for seq, labels in valid_loader:\n",
    "        pred = model(seq)\n",
    "        labels = labels.squeeze(dim=2)\n",
    "        \n",
    "        pred = pred[:,-1]\n",
    "        labels = labels[:,-1]\n",
    "        pred = pred.squeeze()\n",
    "        loss = loss_function(pred, labels)  # MAE误差计算绝对值(预测值  - 真实值)\n",
    "        valid_losss.append(loss.item())\n",
    "        \n",
    "        cur_pred = torch.squeeze(labels, dim=0)\n",
    "        true_valid = torch.cat((true_valid, cur_pred), dim=0)\n",
    "        cur_pred = torch.squeeze(pred, dim=0)\n",
    "        result_valid = torch.cat((result_valid, cur_pred), dim=0)\n",
    "    true_valid = true_valid.detach().numpy() \n",
    "    result_valid  = result_valid.detach().numpy()  \n",
    "          \n",
    "                \n",
    "    valid_loss_cur = np.mean(valid_losss)\n",
    "    return valid_loss_cur, true_valid, result_valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57870ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c46a0a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    " # 网络参数\n",
    "# input_size = norm_data.shape[1]-1\n",
    "input_size = norm_data.shape[1]\n",
    "output_size = predict_day\n",
    "results = []\n",
    "count = len(parameter_combinations) \n",
    "for i in range(len(parameter_combinations)):\n",
    "# for i in range(2):\n",
    "        # 假设你想选择第三个参数组合\n",
    "    selected_params = parameter_combinations[i]\n",
    "\n",
    "    # 然后你就可以按照键来获取对应的值\n",
    "    batch_size = selected_params['Batch_size']\n",
    "    gru_layers = selected_params['Number_of_hidden_layers']\n",
    "    hidden_size = selected_params['Number_of_neurons']\n",
    "    learning_rate = selected_params['Learning_rate']\n",
    "    dropout_rate = selected_params['dropout_rate']\n",
    "    \n",
    "    train_loader, valid_loader = get_train_and_valid_data()\n",
    "    model = GRU(input_size, hidden_size, gru_layers, output_size, dropout_rate, time_step)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    best_loss = 5\n",
    "    \n",
    "    epochs = 150 # 整个训练集被训练多少遍，不考虑早停的前提下\n",
    "    patience = 40               # 训练多少epoch，验证集没提升就停掉\n",
    "    bad_epoch = 0\n",
    "    vl_loss = []\n",
    "    eval_loss = []\n",
    "    for epoch_idx in range(epochs):\n",
    "        train_loss = train(model, train_loader, optimizer)\n",
    "\n",
    "        eval_loss, tru, pre = eval(model, valid_loader)\n",
    "\n",
    "        vl_loss.append(eval_loss)\n",
    "        if eval_loss < best_loss:\n",
    "            best_loss = eval_loss\n",
    "            best_epoch = epoch_idx\n",
    "            best_result_valid = pre\n",
    "            best_true_valid = tru\n",
    "    #         torch.save(model.state_dict(), '../model/best_ANN_trainModel.pth')  # 模型保存\n",
    "        else:\n",
    "            bad_epoch += 1\n",
    "            if bad_epoch >= patience:    # 如果验证集指标连续patience个epoch没有提升，就停掉训练\n",
    "                break\n",
    "    \n",
    "#     x1 = list(range(len(vl_loss)))\n",
    "#     y1 = vl_loss\n",
    "\n",
    "#     # 设置图形标题和坐标轴标签\n",
    "\n",
    "#     plt.xlabel(\"x\")\n",
    "#     plt.ylabel(\"y\")\n",
    "\n",
    "#     plt.plot(x1, y1, color='red', label='val_loss')\n",
    "#     plt.legend()  # 添加图例\n",
    "#     plt.savefig(os.path.join(\"../结果/结果\", f\"image_{i}.png\"))\n",
    "    \n",
    "#     plt.close()  # 关闭图形\n",
    "    \n",
    "    results.append({\n",
    "                    'epoch': best_epoch,\n",
    "                    'loss': best_loss})\n",
    "    print(count , i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6443621e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, params in enumerate(results):\n",
    "    print(f\"参数组合 {idx+1}: {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bae0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并参数组合和结果到一个字典列表\n",
    "combined_params = []\n",
    "for params, result in zip(parameter_combinations, results):\n",
    "    combined_params.append({**params, **result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d3d89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据损失值排序    \n",
    "sorted_params = sorted(combined_params, key=lambda x: x['loss'])\n",
    "\n",
    "# 取前三个\n",
    "top_three_params = sorted_params[:10]\n",
    "\n",
    "print(\"Top Three Parameters:\")\n",
    "for i, param in enumerate(top_three_params, start=1):\n",
    "    print(f\"Rank {i}: {param}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.9",
   "language": "python",
   "name": "python3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
